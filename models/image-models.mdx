---
title: "Image moderation"
description: "Image moderation models are used to detect inappropriate content in images."
---

We are offering three image moderation models.

- An NSFW model that detects a range of common inappropriate content
- A toxicity model that detects general toxic content
- A text model that detects text inside images.

Keep in mind you need to add each model to your project separately.

<Note>

If you need a label/model that is not currently supported, please contact us at
support@moderationapi.com

</Note>

### Response signature

<ResponseField name="flagged" type="boolean" required>
  Whether the image was flagged by any of the models.
</ResponseField>
<ResponseField name="labels" type="array" required>
  An object containing all the label scores.
  <Expandable title="properties">
    <ResponseField name="label" type="string" required>
      The label name.
    </ResponseField>
    <ResponseField name="score" type="number" required>
      The label score from 0 to 1.
    </ResponseField>
  </Expandable>
</ResponseField>
<ResponseField name="texts" type="string[]">
  The text which was detected in the image if the text model is used.
</ResponseField>

```json Image Moderation Response Example:
{
  "flagged": true,
  "labels": [
    {
      "label": "toxicity",
      "score": 0.996117
    },
    {
      "label": "nudity",
      "score": 0.996117
    },
    {
      "label": "gore",
      "score": 0.034441
    },
    {
      "label": "suggestive",
      "score": 0.004936
    },
    {
      "label": "violence",
      "score": 0.00036
    },
    {
      "label": "weapon",
      "score": 0.000079
    },
    {
      "label": "drugs",
      "score": 0.000034
    },
    {
      "label": "hate",
      "score": 0.000032
    },
    {
      "label": "smoking",
      "score": 0.000018
    },
    {
      "label": "alcohol",
      "score": 0.000005
    },
    {
      "label": "text",
      "score": 0.000005
    }
  ]
}
```

## Labels

| Label          | Description                                                          |
| -------------- | -------------------------------------------------------------------- |
| **toxicity**   | Harmful content such as violence, offensive memes, hate, etc.        |
| **nudity**     | Exposed male or female genitalia, female nipples, sexual acts.       |
| **suggestive** | Partial nudity, kissing.                                             |
| **gore**       | Blood, wounds, death.                                                |
| **violence**   | Graphic violence, causing harm, weapons, self-harm.                  |
| **weapon**     | Weapons either in use or displayed.                                  |
| **drugs**      | Drugs such as pills.                                                 |
| **hate**       | Symbols related to nazi, terrorist groups, white supremacy and more. |
| **smoking**    | Smoking or smoking related content.                                  |
| **alcohol**    | Alcohol or alcohol related content.                                  |
| **text**       | Text inside the picture                                              |
