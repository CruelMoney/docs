---
title: "Profanity matching"
sidebarTitle: "Profanity"
description: "Detect and hide swear words in text."
---

> Model key: `profanity`

<Info>
  To detect toxic language without swear words like "You are a monkey", use the
  [toxicity classifier](/models/toxicity).
</Info>

```json Response example
{
  "found": true,
  "mode": "NORMAL",
  "matches": ["bollocks"]
}
```

## Examples

| Value        | Detected by                         | Matches    |
| ------------ | ----------------------------------- | ---------- |
| "fuck"       | `NORMAL`, `SUSPICIOUS` , `PARANOID` | fuck       |
| "ffuuccckkk" | `SUSPICIOUS` , `PARANOID`           | ffuuccckkk |
| "kcuf"       | `PARANOID`                          | kcuf       |

## Wordlist support

This model supports wordlists if you want to allow or block specific words.

You can use the [wordlist editor](/models/wordlists)

## Supported languages

- English `en`

<Note>
  The model might work on other launguages we haven't tested. Feel free to try
  it on launguages that are not listed above and provide us with feedback.
</Note>

<Snippet file="limitations.mdx" />
